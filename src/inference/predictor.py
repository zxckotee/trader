"""
Inference module for MoE cryptocurrency prediction model.
Handles real-time predictions and model evaluation.
"""

import torch
import numpy as np
import pandas as pd
from typing import Dict, List, Tuple, Optional, Any
from pathlib import Path
import json
import time
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')

import sys
sys.path.append(str(Path(__file__).parent.parent))
from models.moe_model import MoECryptoPredictor
from data.preprocessor import CryptoDataPreprocessor
from data.bybit_parser import BybitParser
from utils.device_manager import DeviceManager


class CryptoPredictionService:
    """
    Service for making cryptocurrency price predictions using trained MoE model.
    """
    
    def __init__(self, 
                 model_path: str,
                 preprocessor_path: str,
                 device: Optional[str] = None,
                 force_cpu: bool = False):
        """
        Initialize prediction service.
        
        Args:
            model_path: Path to trained model checkpoint
            preprocessor_path: Path to fitted preprocessor
            device: Device to run inference on ('auto', 'cpu', 'cuda', 'mps')
            force_cpu: Force CPU usage even if GPU is available
        """
        # Setup device
        device_manager = DeviceManager()
        self.device = device_manager.get_optimal_device(force_cpu, device or 'auto')
        device_config = device_manager.configure_for_device(self.device)
        
        print(f"Inference device: {self.device}")
        
        # Load model
        self.model = self._load_model(model_path)
        
        # Load preprocessor
        self.preprocessor = CryptoDataPreprocessor()
        self.preprocessor.load_scalers(preprocessor_path)
        
        # Initialize data parser
        self.parser = BybitParser()
        
        print(f"Prediction service initialized on {self.device}")
    
    def _load_model(self, model_path: str) -> MoECryptoPredictor:
        """Load trained model from checkpoint."""
        checkpoint = torch.load(model_path, map_location=self.device)
        
        # Extract model configuration from checkpoint
        config = checkpoint.get('config', {})\n        \n        # Create model (you might need to adjust this based on your saved config)\n        model = MoECryptoPredictor(\n            input_dim=checkpoint.get('input_dim', 50),  # Adjust based on your features\n            timeframes=['5m', '30m', '1h', '1d', '1w']\n        )\n        \n        # Load state dict\n        model.load_state_dict(checkpoint['model_state_dict'])\n        model.to(self.device)\n        model.eval()\n        \n        return model\n    \n    def get_latest_data(self, \n                       symbol: str,\n                       timeframes: List[str],\n                       lookback_hours: int = 24) -> Dict[str, pd.DataFrame]:\n        \"\"\"\n        Get latest market data for prediction.\n        \n        Args:\n            symbol: Trading pair symbol\n            timeframes: List of timeframes to fetch\n            lookback_hours: Hours of historical data to fetch\n            \n        Returns:\n            Dictionary mapping timeframes to DataFrames\n        \"\"\"\n        end_time = datetime.now()\n        start_time = end_time - timedelta(hours=lookback_hours)\n        \n        data = {}\n        \n        for tf in timeframes:\n            try:\n                df = self.parser.collect_historical_data(\n                    symbol=symbol,\n                    timeframe=tf,\n                    start_date=start_time.strftime('%Y-%m-%d'),\n                    end_date=end_time.strftime('%Y-%m-%d')\n                )\n                \n                if not df.empty:\n                    data[tf] = df\n                else:\n                    print(f\"No data available for {tf}\")\n                    \n            except Exception as e:\n                print(f\"Error fetching {tf} data: {e}\")\n        \n        return data\n    \n    def preprocess_for_inference(self, \n                               data_dict: Dict[str, pd.DataFrame]) -> Dict[str, torch.Tensor]:\n        \"\"\"\n        Preprocess data for model inference.\n        \n        Args:\n            data_dict: Dictionary mapping timeframes to DataFrames\n            \n        Returns:\n            Dictionary mapping timeframes to input tensors\n        \"\"\"\n        processed_inputs = {}\n        \n        for tf, df in data_dict.items():\n            try:\n                # Process single timeframe\n                processed = self.preprocessor.process_timeframe_data(\n                    df, tf, fit_scaler=False\n                )\n                \n                if processed['X'].shape[0] > 0:\n                    # Take the last sequence for prediction\n                    last_sequence = processed['X'][-1:]\n                    processed_inputs[tf] = torch.FloatTensor(last_sequence).to(self.device)\n                    \n            except Exception as e:\n                print(f\"Error preprocessing {tf} data: {e}\")\n        \n        return processed_inputs\n    \n    def predict(self, \n               symbol: str,\n               timeframes: Optional[List[str]] = None,\n               return_expert_outputs: bool = False) -> Dict[str, Any]:\n        \"\"\"\n        Make price predictions for given symbol.\n        \n        Args:\n            symbol: Trading pair symbol (e.g., 'BTCUSDT')\n            timeframes: List of timeframes to use (default: all)\n            return_expert_outputs: Whether to return individual expert predictions\n            \n        Returns:\n            Dictionary with predictions and metadata\n        \"\"\"\n        if timeframes is None:\n            timeframes = ['5m', '30m', '1h', '1d', '1w']\n        \n        # Get latest data\n        print(f\"Fetching latest data for {symbol}...\")\n        data_dict = self.get_latest_data(symbol, timeframes)\n        \n        if not data_dict:\n            raise ValueError(f\"No data available for {symbol}\")\n        \n        # Preprocess data\n        print(\"Preprocessing data...\")\n        inputs = self.preprocess_for_inference(data_dict)\n        \n        if not inputs:\n            raise ValueError(\"No valid preprocessed data\")\n        \n        # Make predictions\n        print(\"Making predictions...\")\n        with torch.no_grad():\n            outputs = self.model(inputs)\n        \n        # Process outputs\n        predictions = {\n            'symbol': symbol,\n            'timestamp': datetime.now().isoformat(),\n            'timeframes_used': list(inputs.keys()),\n            'aggregated_predictions': {\n                'price_change_pct': float(outputs['price_change'].cpu().item() * 100),\n                'direction_prob': torch.softmax(outputs['direction_logits'], dim=-1).cpu().numpy().tolist(),\n                'predicted_direction': 'up' if torch.argmax(outputs['direction_logits']).item() == 1 else 'down',\n                'volatility': float(outputs['volatility'].cpu().item()),\n                'confidence': float(torch.max(torch.softmax(outputs['direction_logits'], dim=-1)).cpu().item())\n            }\n        }\n        \n        # Add expert weights if available\n        if 'expert_weights' in outputs and outputs['expert_weights'] is not None:\n            expert_weights = outputs['expert_weights'].cpu().numpy()[0]\n            predictions['expert_weights'] = {\n                tf: float(weight) for tf, weight in zip(timeframes, expert_weights)\n            }\n        \n        # Add individual expert outputs if requested\n        if return_expert_outputs and 'expert_outputs' in outputs:\n            expert_preds = {}\n            for tf, expert_out in outputs['expert_outputs'].items():\n                expert_preds[tf] = {\n                    'price_change_pct': float(expert_out['price_change'].cpu().item() * 100),\n                    'direction_prob': torch.softmax(expert_out['direction_logits'], dim=-1).cpu().numpy().tolist(),\n                    'predicted_direction': 'up' if torch.argmax(expert_out['direction_logits']).item() == 1 else 'down',\n                    'volatility': float(expert_out['volatility'].cpu().item())\n                }\n            predictions['expert_predictions'] = expert_preds\n        \n        return predictions\n    \n    def predict_multiple_symbols(self, \n                               symbols: List[str],\n                               timeframes: Optional[List[str]] = None) -> Dict[str, Dict[str, Any]]:\n        \"\"\"\n        Make predictions for multiple symbols.\n        \n        Args:\n            symbols: List of trading pair symbols\n            timeframes: List of timeframes to use\n            \n        Returns:\n            Dictionary mapping symbols to predictions\n        \"\"\"\n        results = {}\n        \n        for symbol in symbols:\n            try:\n                print(f\"\\nProcessing {symbol}...\")\n                predictions = self.predict(symbol, timeframes)\n                results[symbol] = predictions\n            except Exception as e:\n                print(f\"Error predicting {symbol}: {e}\")\n                results[symbol] = {'error': str(e)}\n        \n        return results\n    \n    def evaluate_predictions(self, \n                           test_data: Dict[str, Dict[str, np.ndarray]],\n                           num_samples: int = 100) -> Dict[str, float]:\n        \"\"\"\n        Evaluate model performance on test data.\n        \n        Args:\n            test_data: Test dataset\n            num_samples: Number of samples to evaluate\n            \n        Returns:\n            Dictionary with evaluation metrics\n        \"\"\"\n        self.model.eval()\n        \n        all_price_preds = []\n        all_price_targets = []\n        all_direction_preds = []\n        all_direction_targets = []\n        \n        with torch.no_grad():\n            for i in range(min(num_samples, len(next(iter(test_data.values()))['X']))):\n                # Prepare inputs\n                inputs = {}\n                targets = {}\n                \n                for tf in test_data.keys():\n                    if i < len(test_data[tf]['X']):\n                        inputs[tf] = torch.FloatTensor(test_data[tf]['X'][i:i+1]).to(self.device)\n                        if not targets:  # Use first timeframe as target\n                            y = test_data[tf]['y'][i]\n                            targets = {\n                                'price_change': y[0],\n                                'direction': int(y[1]),\n                                'volatility': y[2]\n                            }\n                \n                if inputs:\n                    # Make prediction\n                    outputs = self.model(inputs)\n                    \n                    # Collect predictions\n                    all_price_preds.append(float(outputs['price_change'].cpu().item()))\n                    all_price_targets.append(targets['price_change'])\n                    \n                    pred_direction = int(torch.argmax(outputs['direction_logits']).cpu().item())\n                    all_direction_preds.append(pred_direction)\n                    all_direction_targets.append(targets['direction'])\n        \n        # Calculate metrics\n        from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, accuracy_score\n        \n        metrics = {\n            'price_mse': mean_squared_error(all_price_targets, all_price_preds),\n            'price_mae': mean_absolute_error(all_price_targets, all_price_preds),\n            'price_r2': r2_score(all_price_targets, all_price_preds),\n            'direction_accuracy': accuracy_score(all_direction_targets, all_direction_preds),\n            'num_samples': len(all_price_preds)\n        }\n        \n        return metrics\n    \n    def save_predictions(self, \n                       predictions: Dict[str, Any],\n                       filepath: str) -> None:\n        \"\"\"\n        Save predictions to JSON file.\n        \n        Args:\n            predictions: Prediction results\n            filepath: Output file path\n        \"\"\"\n        with open(filepath, 'w') as f:\n            json.dump(predictions, f, indent=2, default=str)\n        \n        print(f\"Predictions saved to {filepath}\")\n\n\nclass RealTimePredictionService:\n    \"\"\"\n    Service for continuous real-time predictions.\n    \"\"\"\n    \n    def __init__(self, \n                 predictor: CryptoPredictionService,\n                 symbols: List[str],\n                 prediction_interval: int = 300):  # 5 minutes\n        \"\"\"\n        Initialize real-time service.\n        \n        Args:\n            predictor: Prediction service instance\n            symbols: List of symbols to monitor\n            prediction_interval: Prediction interval in seconds\n        \"\"\"\n        self.predictor = predictor\n        self.symbols = symbols\n        self.prediction_interval = prediction_interval\n        self.prediction_history = []\n    \n    def run_continuous_predictions(self, \n                                 duration_hours: Optional[int] = None) -> None:\n        \"\"\"\n        Run continuous predictions.\n        \n        Args:\n            duration_hours: Duration to run (None for indefinite)\n        \"\"\"\n        start_time = time.time()\n        \n        print(f\"Starting real-time predictions for {self.symbols}\")\n        print(f\"Prediction interval: {self.prediction_interval} seconds\")\n        \n        try:\n            while True:\n                current_time = time.time()\n                \n                # Check if duration limit reached\n                if duration_hours and (current_time - start_time) > duration_hours * 3600:\n                    break\n                \n                print(f\"\\n=== {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} ===\")\n                \n                # Make predictions for all symbols\n                predictions = self.predictor.predict_multiple_symbols(self.symbols)\n                \n                # Store predictions\n                self.prediction_history.append({\n                    'timestamp': datetime.now().isoformat(),\n                    'predictions': predictions\n                })\n                \n                # Display results\n                for symbol, pred in predictions.items():\n                    if 'error' not in pred:\n                        agg = pred['aggregated_predictions']\n                        print(f\"{symbol}: {agg['predicted_direction']} \"\n                              f\"({agg['price_change_pct']:.2f}%) \"\n                              f\"confidence: {agg['confidence']:.3f}\")\n                    else:\n                        print(f\"{symbol}: Error - {pred['error']}\")\n                \n                # Wait for next prediction\n                time.sleep(self.prediction_interval)\n                \n        except KeyboardInterrupt:\n            print(\"\\nStopping real-time predictions...\")\n        \n        # Save prediction history\n        history_file = f\"prediction_history_{int(time.time())}.json\"\n        with open(history_file, 'w') as f:\n            json.dump(self.prediction_history, f, indent=2)\n        \n        print(f\"Prediction history saved to {history_file}\")\n\n\ndef main():\n    \"\"\"\n    Example usage of prediction service.\n    \"\"\"\n    # Initialize prediction service\n    try:\n        predictor = CryptoPredictionService(\n            model_path=\"./models/best_model.pt\",\n            preprocessor_path=\"./data/scalers.pkl\"\n        )\n        \n        # Single prediction\n        print(\"Making single prediction for BTCUSDT...\")\n        prediction = predictor.predict(\n            symbol=\"BTCUSDT\",\n            return_expert_outputs=True\n        )\n        \n        print(\"\\nPrediction Results:\")\n        print(json.dumps(prediction, indent=2, default=str))\n        \n        # Multiple symbols\n        symbols = [\"BTCUSDT\", \"ETHUSDT\", \"ADAUSDT\"]\n        print(f\"\\nMaking predictions for {symbols}...\")\n        \n        multi_predictions = predictor.predict_multiple_symbols(symbols)\n        \n        for symbol, pred in multi_predictions.items():\n            if 'error' not in pred:\n                agg = pred['aggregated_predictions']\n                print(f\"{symbol}: {agg['predicted_direction']} \"\n                      f\"({agg['price_change_pct']:.2f}%) \"\n                      f\"confidence: {agg['confidence']:.3f}\")\n        \n        # Save results\n        predictor.save_predictions(multi_predictions, \"latest_predictions.json\")\n        \n    except Exception as e:\n        print(f\"Error: {e}\")\n        print(\"Make sure you have trained a model and have the required files.\")\n\n\nif __name__ == \"__main__\":\n    main()
